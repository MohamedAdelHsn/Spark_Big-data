# Spark Applications
Apache Spark is a cluster computing platform designed to be fast and general-
purpose. 
Spark extends the popular MapReduce model to efficiently sup‐
port more types of computations, including interactive queries and stream process‐
ing. Speed is important in processing large datasets, as it means the difference
between exploring data interactively and waiting minutes or hours. One of the main
features Spark offers for speed is the ability to run computations in memory, but the
system is also more efficient than MapReduce for complex applications running on
disk.
## setup spark in linux Ubuntu
if you don't install spark u can [visit this](https://medium.com/@josemarcialportilla/installing-scala-and-spark-on-ubuntu-5665ee4b62b1)
